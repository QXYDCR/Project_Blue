{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wl6c-Xah9gcO"
   },
   "source": [
    "#**Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "XhNeppG6Eo9B",
    "outputId": "f9749cdc-3bb7-4879-c63c-0b03e4e72c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"One of the best movie of all time. Period.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dh7FuMaLAqb2"
   },
   "source": [
    "#**Text PreProcessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Qz5iqQpoYVn"
   },
   "source": [
    "### (1) Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qiF5qTEU8eI3",
    "outputId": "9c337c56-8564-4db4-df98-b34434a19fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the best movie of all time Period\n"
     ]
    }
   ],
   "source": [
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "for x in sentence: \n",
    "  if x in punctuations: \n",
    "    sentence = sentence.replace(x, \"\")\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E162bD8uohb1"
   },
   "source": [
    "### (2) Change Case + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EKVrpopOEp3h",
    "outputId": "fa0a915b-6876-4798-f6d6-78b25b38d0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'best', 'movie', 'of', 'all', 'time', 'period']\n"
     ]
    }
   ],
   "source": [
    "Tokens = nltk.word_tokenize(sentence.lower())\n",
    "print(Tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juVoKR1JooNE"
   },
   "source": [
    "####(3) Removing Stop Words - a, an, the, are, is etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q3DgjGz9FgT_",
    "outputId": "0d00c0d6-9757-4046-c0e1-fe0bf9376100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'best', 'movie', 'time', 'period']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "clean_Tokens = [word for word in Tokens if word not in stop_words]\n",
    "print(clean_Tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTbjBljvosx8"
   },
   "source": [
    "####(4) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mjItEe7DszZI",
    "outputId": "5db4bff3-0759-4e00-80f6-e80b7af12503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'best', 'movie', 'time', 'period']\n"
     ]
    }
   ],
   "source": [
    "lemma = [lemmatizer.lemmatize(word) for word in clean_Tokens]\n",
    "\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rr4iL2yBoxp8"
   },
   "source": [
    "####(5) POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "enSDIKd6GxV-",
    "outputId": "88973ba9-c5d5-42fb-c590-905320be7d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'CD'), ('best', 'JJS'), ('movie', 'NN'), ('time', 'NN'), ('period', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_val = nltk.pos_tag(lemma)\n",
    "print(pos_val)\n",
    "\n",
    "pos=neg=obj=count=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uggZN4TMvnDv"
   },
   "source": [
    "#**Functions for Sentiment Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QsFpcxUKQZJ"
   },
   "outputs": [],
   "source": [
    "# Convert between the PennTreebank tags to simple Wordnet tags\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpz9GfA3Kc22"
   },
   "outputs": [],
   "source": [
    "# Returns list of pos-neg and objective score. But returns empty list if not present in senti wordnet.\n",
    "def get_sentiment(word,tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    \n",
    "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "        return []\n",
    "\n",
    "    #Lemmatization\n",
    "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "    if not lemma:\n",
    "        return []\n",
    "\n",
    "    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
    "    #Synset instances are the groupings of synonymous words that express the same concept. \n",
    "    #Some of the words have only one Synset and some have several.\n",
    "    synsets = wn.synsets(word, pos=wn_tag)\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Take the first sense, the most common\n",
    "    synset = synsets[0]\n",
    "    swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B7nuHaHLKjCH",
    "outputId": "3e190ca3-1ef8-4bad-ea0e-3e97cff3e174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['best.a.01', 0.75, 0.0, 0.25], ['movie.n.01', 0.0, 0.0, 1.0], ['time.n.01', 0.0, 0.0, 1.0], ['time_period.n.01', 0.125, 0.125, 0.75]]\n"
     ]
    }
   ],
   "source": [
    "senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
    "print(senti_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9iCiFBqvwKt"
   },
   "source": [
    "#**Aggregating Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdjCUMZuoS9l"
   },
   "outputs": [],
   "source": [
    "for i in range(len(senti_val)):\n",
    "  try:\n",
    "    pos = pos + senti_val[i][1]\n",
    "    neg = neg + senti_val[i][2]\n",
    "    obj = obj + senti_val[i][3]\n",
    "  \n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yGefTwhdofsw",
    "outputId": "611cbc5b-c9b9-487e-f049-bfe053a599fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive weight : 0.875 \n",
      "Negative weight : 0.125 \n",
      "Sentiment of the statement is 0.75 \n"
     ]
    }
   ],
   "source": [
    "print(\"Positive weight : {0} \".format(pos))\n",
    "print(\"Negative weight : {0} \".format(neg))\n",
    "print(\"Sentiment of the statement is {0} \".format(pos - neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkYTwqFpShh5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SentimentAnalysis_SentiWordnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
